{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":12040,"status":"ok","timestamp":1665618955158,"user":{"displayName":"Luís Parra","userId":"08626710792356489822"},"user_tz":-60},"id":"oo_kIb5EV3yq"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import pickle\n","import math\n","import sklearn\n","import plotly \n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","\n","from sklearn.svm import SVC\n","from tensorflow import keras\n","from keras.models import Sequential\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.models import Sequential, save_model, load_model\n","from keras import Input \n","from keras.layers import Dense, SimpleRNN\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from pandas import read_csv\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2106,"status":"ok","timestamp":1665621000725,"user":{"displayName":"Luís Parra","userId":"08626710792356489822"},"user_tz":-60},"id":"iA88-93aPCnV","outputId":"09e37dff-9828-40e0-a10a-b1ff134cde9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of LDA classifier on training set: 0.80\n","Accuracy of LDA classifier on test set: 0.80\n","4\n"]}],"source":["\n","# Open all relevant files\n","f = open('radar_count_2022_09_01.csv') # Needs to be imported manually, not in the Git\n","df = pd.read_csv(f)\n","df=df.drop(['entity_id'], axis=1)\n","numberList = [0, 1, 2, 3, 4, 5]\n","\n","# Randomly shuffle the list\n","df['randNumCol'] = random.choices(numberList, weights=(80, 10, 5, 3, 1, 1), k=330821)\n","\n","# Attribute feature names\n","feature_names=['faixa', 'vehiclelight', 'speedlight', 'vehicleheavy', 'speedheavy', 'vehicleothers', 'speedothers', 'accelerationlight', 'accelerationheavy', 'accelerationothers']\n","\n","X = df[feature_names]\n","Y = df['randNumCol']\n","\n","# Split dataset into training set and test set\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n","\n","# Create Decision Tree classifer object\n","scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Linear Discriminant Analysis\n","lda = LinearDiscriminantAnalysis()\n","lda.fit(X_train, y_train)\n","\n","# Print the accuracy of the model\n","print('Accuracy of LDA classifier on training set: {:.2f}'\n","     .format(lda.score(X_train, y_train)))\n","print('Accuracy of LDA classifier on test set: {:.2f}'\n","     .format(lda.score(X_test, y_test)))\n","test=[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","print(lda.predict(np.array(test).reshape(1, -1))[0])\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"elapsed":964764,"status":"error","timestamp":1665622188901,"user":{"displayName":"Luís Parra","userId":"08626710792356489822"},"user_tz":-60},"id":"Mm_6MOqbjg8v","outputId":"c5f4a8fa-12e0-456e-9fc2-d02dadbd1eef"},"outputs":[{"name":"stdout","output_type":"stream","text":["1703/1703 [==============================] - 924s 519ms/step - loss: 0.0186\n"]},{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-eb546a06a2f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0munscaled_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'radar_count_2022_09_01.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munscaled_x_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'randNumCo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munscaled_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'randNumCo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mx_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mx_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'unscaled_x_training_data' is not defined"]}],"source":["# Read from CSV\n","training_data = pd.read_csv('radar_count_2022_09_01.csv')\n","n = 330100\n","training_data.drop(training_data.tail(n).index,\n","        inplace = True)\n","training_data = training_data.iloc[:, [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]].values\n","\n","# Create MinMaxScaler object\n","scaler = MinMaxScaler()\n","training_data = scaler.fit_transform(training_data.reshape(-1, 1))\n","x_training_data = []\n","y_training_data =[]\n","\n","# Run through training data\n","for i in range(400, len(training_data)):\n","\n","    x_training_data.append(training_data[i-400:i, 0])\n","\n","    y_training_data.append(training_data[i, 0])\n","\n","x_training_data = np.array(x_training_data)\n","\n","y_training_data = np.array(y_training_data)\n","\n","x_training_data = np.reshape(x_training_data, (x_training_data.shape[0], \n","\n","                                               x_training_data.shape[1], \n","\n","                                               1))\n","\n","\n","# Create the RNN\n","rnn = Sequential()\n","rnn.add(LSTM(units = 5, return_sequences = True, input_shape = (x_training_data.shape[1], 1)))\n","rnn.add(Dropout(0.2))\n","rnn.add(LSTM(units = 5, return_sequences = True))\n","rnn.add(Dropout(0.2))\n","rnn.add(LSTM(units = 5, return_sequences = True))\n","rnn.add(Dropout(0.2))\n","rnn.add(LSTM(units = 5))\n","rnn.add(Dropout(0.2))\n","rnn.add(Dense(units = 1))\n","rnn.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","\n","# Train the RNN\n","rnn.fit(x_training_data, y_training_data, epochs = 1, batch_size = 4)\n","\n","# Read from CSV\n","test_data = pd.read_csv('radar_count_2022_09_01.csv')\n","test_data = test_data.iloc[:, [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]].values\n","unscaled_training_data = pd.read_csv('radar_count_2022_09_01.csv')\n","unscaled_test_data = pd.read_csv('radar_count_2022_09_01.csv')\n","\n","# Add all data to the test data\n","all_data = pd.concat((unscaled_training_data['randNumCo'], unscaled_test_data['randNumCo']), axis = 0)\n","x_test_data = all_data[len(all_data) - len(test_data) - 40:].values\n","x_test_data = np.reshape(x_test_data, (-1, 1))\n","x_test_data = scaler.transform(x_test_data)\n","\n","final_x_test_data = []\n","\n","# Run through new test data\n","for i in range(40, len(x_test_data)):\n","\n","    final_x_test_data.append(x_test_data[i-40:i, 0])\n","\n","final_x_test_data = np.array(final_x_test_data)\n","\n","final_x_test_data = np.reshape(final_x_test_data, (final_x_test_data.shape[0], \n","\n","                                               final_x_test_data.shape[1], \n","\n","                                               1))\n","\n","# Predict the new test data\n","predictions = rnn.predict(final_x_test_data)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMNu59zkij+JqUSYmbyPXIP","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.7 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.7"},"vscode":{"interpreter":{"hash":"461c938d22c9c9838b690be7822db5003fc45b073482fbe043aaebcef8c0f4de"}}},"nbformat":4,"nbformat_minor":0}
